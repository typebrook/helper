#! /bin/bash

# TODO
# - Use suggested block to wrap data:
#   https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api
# - Cowork with https://github.com/openai/chatgpt-retrieval-plugin
# - History for prompt

# Necessary commands
stacks=( curl jq sed )

# User can dynamically change these options for API call
configurable_options=( model behavior temperature max_tokens stream context )

# If script is interupt by SIGINT, simply print leave message
trap _print_leave_message INT

# If any stack is missing, exit with 2
_check_stacks() {
  for command in "${stacks[@]}"; do
    which "$command" &>/dev/null && continue
    echo "$command" is needed
    exit 2
  done
}

# Function for printing helper message
_print_helper_message() {
  cat <<EOF
Usage: gpt [-h] [-m MODEL] [-m4] [-b BEHAVIOR] [-t temperature]
           [-M MAX_TOKENS] [-s] [MESSAGE]

Env:
  OPENAI_API_KEY    Generate API key from https://platform.openai.com/account/api-keys
                    (Required)

Options:
  -h, --help        show this help message and exit

  -m|--model        specify model, available:
                    gpt-4, gpt-4-0314, gpt-4-32k, gpt-4-32k-0314, 
                    gpt-3.5-turbo, gpt-3.5-turbo-0301
                    (Defaults to gpt-3.5-turbo)

  -m4               Use model gpt-4 
                    
  -b|--behavior     How model behave on response, for example:
                      "You are a helpful assistant."
                    (Defaults to "You are a helpful programming assistant")

  -t|--temperature  Value between 0 and 2. Higher values like 0.8 will make the 
                    output more random, while lower values like 0.2 will make it 
                    more focused and deterministic.
                    (Defaults to 0.7)

  -M|--max_tokens   The maximum number of tokens to generate in the completion.
                    (Defaults to 1024)

  -s|--skip         Skip message, STDIN would be treated as your message

  -S|--stream       Use stream mode. If this is set, token usage would not be shown

  -c|--context      Number of messages in session. If it is set, API calls only 
                    contains limited previous chats. If it is 1, then GPT only get
                    your latest prompt input. (By default, API calls use the 
                    whole previous chats, which is not friendly to token usage)

  -v|--verbose      If set, print token usage after each completion.

  *                 The other arguments would be treated as message content.
                    If no message is specified, user should input content by hands.
                    If STDIN is given, it would be append to the end of message.

Special Input:
  .c                A special prompt of options shows up. User can dynamically modify 
                    option values for API calls.

  .h                Ask gpt the usage of this script

Reference: https://platform.openai.com/docs/api-reference/completions
EOF
}

# Message when user exit prompt
_print_leave_message(){
  echo -en "\n\nChat ends. " 
  if [ "$stream" = false ]; then
    tokens=$(jq '.usage? // empty | .total_tokens' "$cache" | paste -sd+ | bc)
    echo -en "${tokens:-0} tokens used. "
  fi
  echo Session is cached in "$cache"
  exit 0
}

# A prompt for option configuration
_configure_options() {
  # Apply original trap action, and exit this prompt
  trap 'trap _print_leave_message SIGINT; echo; return' INT
  # Hint message
  echo 'List of options: (Use Ctrl-C to exit)'

  # Print all available options
  index=0
  for option in "${configurable_options[@]}"; do
    echo -e "$index." "$option:\t" "$(eval "echo \$$option")"
    (( index+=1 ))
  done

  # Prompt for user input
  while true; do
    echo
    read -e -r -p "Modify which option? (0~$((index-1))) " selection
    if [[ "$selection" =~ ^[0-9]+$ ]] && \
       (( "$selection" >= 0 && "$selection" < "$index" )); then
      local field=${configurable_options[$selection]}
      eval "read -e -r -p '$field: ' $field"
    else
      echo Wrong Input
    fi
  done
}

# Get latest content for completion
_get_content() {

  # Read data from STDIN
  [ ! -t 0 ] && data="$(cat)"

  if [ ! "$SKIP_INPUT" = true ] ; then
    # Read content from terminal
    while true; do
      read -e -r -p "Let's Chat: " content </dev/tty
      if [ "$content" = .c ]; then
        echo -e '\n======\n'
        _configure_options
        echo -e '\n======\n'
        continue
      elif [ "$content" = .h ]; then
        content="What does the following script used for? Show me how to use it?"
        echo -n "$content"
        content="$content\n\n$(cat "$0")"
      elif [ -n "$content" ]; then
        break
      else
        continue
      fi
    done
  # Exit 1 when "--skip" is specified, but no STDIN and CONTENT is given
  elif [[ "$round" -eq 1 && -z "${content}${data}" ]]; then
    echo -e "No data from STDIN\n"
    exit 1;
  fi

  # Use STDIN as content if "--skip" is given
  if [ "$SKIP_INPUT" = true ] && [ -z "$content" ] ; then
    content="$data"
    echo -e "$content"
  else
    content="$(printf "%s${data:+\\n\\n}%s" "$content" "$data")"
    [ -n "$data" ] && echo "$data"
  fi
}

_API_call() {
  curl https://api.openai.com/$ROUTE \
    --silent \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $OPENAI_API_KEY" \
    -d "$body"
}

_process_completion() {
  if [ "$stream" = true ]; then
    sed -E 's/data: (\[DONE\])?//g;/^$/d' | \
    jq . | tee -a "$cache" | \
    jq -jr '.choices?[0]?.delta?.content? // empty'
  else
    jq . | tee -a "$cache" | \
    jq -jr .choices[0].message.content
  fi
}

# Check OPENAI API KEY in env
# Exit with 6 (configuration issue) if it is not set
[ -z "$OPENAI_API_KEY" ] && which token &>/dev/null && OPENAI_API_KEY=$(token openai)
[ -z "$OPENAI_API_KEY" ] && { echo API KEY not specified; exit 6; }

# Parse arguments
while [ "$#" -gt 0 ]; do
  case "$1" in
    -m|--model)
      model="$2"
      shift 2
      ;;
    -m4)
      model="gpt-4"
      shift 1
      ;;
    -b|--behavior)
      behavior="$2"
      shift 2
      ;;
    -t|--temperature)
      temperature="$2"
      shift 2
      ;;
    -M|--max_tokens)
      max_tokens="$2"
      shift 2
      ;;
    -s|--skip)
      SKIP_INPUT=true
      shift 1
      ;;
    -S|--stream)
      stream=true
      shift 1
      ;;
    -c|--context)
      context=$2
      shift 2
      ;;
    -v|--verbose)
      VERBOSE=true
      shift 1
      ;;
    -h|--help)
      _print_helper_message
      exit 0
      ;;
    *)
      SKIP_INPUT=true
      content="$1"
      shift 1
      ;;
  esac
done

# Make sure necessary commands exist
_check_stacks

# Set variables in API calls
ROUTE=v1/chat/completions
model=${model:-gpt-3.5-turbo}
behavior="${behavior:-You are a helpful programming assistant}"
temperature=${temperature:-0.7}
max_tokens=${max_tokens:-1024}
stream=${stream:-false}
INDEX=

# Prepare for chat session
cache=$(mktemp) && touch "$cache" 
#trap "rm $cache" EXIT
session=()
round=1

# Use while to keep chat session
while true; do
  _get_content
  echo

  # User must input by hands in the following rounds
  SKIP_INPUT=false

  # Put user message into session
  user_message="$(cat <<EOF
{"role": "user", "content": $(printf '%s' "$content" | jq -sR .)}
EOF
  )"
  session+=("$user_message")

  # If context is specified, use INDEX to get specified range from session
  if [ -n "$context" ]; then
    INDEX="-$([ "${#session[@]}" -le "$context" ] && echo ${#session[@]} || echo $(( "$context" + 1 )))"
  fi

  # Create request body
  # Consider quotes, back slashes, use jq to ensure content texts are OK to put in JSON
  body="$(cat <<EOF
{
   "model": "$model",
   "messages": [
     {"role": "system", "content": $(echo "$behavior" | jq -sR .)},
     $(IFS=','; echo "${session[*]: $INDEX}")
   ],
   "temperature": $temperature,
   "max_tokens": $max_tokens,
   "stream": $stream
}
EOF
  )"
  # Append request body into cache
  echo "$body" >>"$cache"

  # Use Yellow color to print completion from GPT
  echo -en '\e[33m'
  _API_call | _process_completion
  echo -e '\e[0m\n'

  if [ "$VERBOSE" = true ]; then
    tokens=$(jq -s '.[-1].usage? // empty | .total_tokens' "$cache")
    echo -e "$tokens token used.\n"
  fi

  # Append newest message into session
  assistant_message="$(cat <<EOF
{"role": "assistant", "content": $(jq -sr '.[-1].choices[0].message.content' "$cache" | jq -sR .)}
EOF
  )"
  session+=("$assistant_message")

  (( round+=1 ))
done
